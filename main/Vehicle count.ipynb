{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "folder_path = cv2.imread(\"mlproject\\\\csvfile\\\\images\")\n",
    "# List all files in the directory\n",
    "\n",
    "image_files = os.listdir(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"C:\\\\Users\\\\manoj\\\\Downloads\\\\yolov3.cfg\"\n",
    "weights_path = \"C:\\\\Users\\\\manoj\\\\Downloads\\\\yolov3.weights\"\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n",
    "\n",
    "# Load class labels (COCO dataset labels for YOLOv3)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    # Check if the file is an image (you can add more extensions if needed)\n",
    "    if image_file.endswith(\".jpg\") or image_file.endswith(\".png\") or image_file.endswith(\".jpeg\"):\n",
    "        image_path = os.path.join(folder_path, image_file)  # Full path to the image\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Check if the image was loaded successfully\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load the image {image_file}\")\n",
    "            continue  # Skip this image if it can't be loaded\n",
    "        blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Perform inference or other operations with the image\n",
    "        # For example: Perform object detection, count vehicles, etc.\n",
    "        \n",
    "        print(f\"Processed image: {image_file}\")\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # Initialize lists to hold detection data\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Iterate over all detections\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m \u001b[43mouts\u001b[49m:\n\u001b[0;32m      3\u001b[0m    \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m out:\n\u001b[0;32m      4\u001b[0m        scores \u001b[38;5;241m=\u001b[39m detection[\u001b[38;5;241m5\u001b[39m:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outs' is not defined"
     ]
    }
   ],
   "source": [
    " # Iterate over all detections\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)  # Get the index of the highest score\n",
    "        confidence = scores[class_id]  # Get the confidence value for that class\n",
    "                \n",
    " # If confidence is above a threshold (e.g., 0.5), we consider this a valid detection\n",
    "        if confidence > 0.5:\n",
    " # Get the bounding box coordinates (center x, center y, width, height)\n",
    "            center_x = int(detection[0] * image.shape[1])\n",
    "            center_y = int(detection[1] * image.shape[0])\n",
    "            width = int(detection[2] * image.shape[1])\n",
    "            height = int(detection[3] * image.shape[0])\n",
    "\n",
    "# Rectangle coordinates (top-left corner)\n",
    "            x = int(center_x - width / 2)\n",
    "            y = int(center_y - height / 2)\n",
    "\n",
    "# Save the detection results\n",
    "            boxes.append([x, y, width, height])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)# Perform forward pass to get the output layer predictions\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Folder path where the images are stored\n",
    "folder_path = cv2.imread(\"mlproject\\\\csvfile\\\\images\")# Adjust this path\n",
    "\n",
    "# YOLOv3 config and weights file paths\n",
    "cfg_path = \"C:\\\\Users\\\\manoj\\\\Downloads\\\\yolov3.cfg\"\n",
    "weights_path = \"C:\\\\Users\\\\manoj\\\\Downloads\\\\yolov3.weights\"\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n",
    "\n",
    "# Load class labels (COCO dataset labels for YOLOv3)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# List all files in the folder\n",
    "image_files = os.listdir(folder_path)\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for image_file in image_files:\n",
    "    # Filter for image files (you can add more formats)\n",
    "    if image_file.endswith(\".jpg\") or image_file.endswith(\".png\") or image_file.endswith(\".jpeg\"):\n",
    "        image_path = os.path.join(folder_path, image_file)  # Full path to the image\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Check if the image was loaded successfully\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load the image {image_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Preprocess the image: Convert to blob format for YOLOv3\n",
    "        blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        \n",
    "        # Perform forward pass to get the output layer predictions\n",
    "        outs = net.forward(output_layers)  # This is where we get the outputs\n",
    "\n",
    "        # Initialize lists to hold detection data\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        # Iterate over all detections\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)  # Get the index of the highest score\n",
    "                confidence = scores[class_id]  # Get the confidence value for that class\n",
    "                \n",
    "                # If confidence is above a threshold (e.g., 0.5), we consider this a valid detection\n",
    "                if confidence > 0.5:\n",
    "                    # Get the bounding box coordinates (center x, center y, width, height)\n",
    "                    center_x = int(detection[0] * image.shape[1])\n",
    "                    center_y = int(detection[1] * image.shape[0])\n",
    "                    width = int(detection[2] * image.shape[1])\n",
    "                    height = int(detection[3] * image.shape[0])\n",
    "\n",
    "                    # Rectangle coordinates (top-left corner)\n",
    "                    x = int(center_x - width / 2)\n",
    "                    y = int(center_y - height / 2)\n",
    "\n",
    "                    # Save the detection results\n",
    "                    boxes.append([x, y, width, height])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply non-maximum suppression (NMS) to remove redundant overlapping boxes\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
    "\n",
    "        # Draw bounding boxes and labels on the image\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(class_ids[i])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = (0, 255, 0)  # Green bounding box\n",
    "\n",
    "            # Draw the rectangle and put the label\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, label + \" \" + confidence, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Show the image with the bounding boxes (optional)\n",
    "        cv2.imshow(\"Detection\", image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        # Optionally save the image with detections\n",
    "        output_path = os.path.join(folder_path, \"output\", image_file)  # Make sure 'output' folder exists\n",
    "        cv2.imwrite(output_path, image)\n",
    "        print(f\"Processed {image_file}\")\n",
    "    \n",
    "# Close all OpenCV windows after processing\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes and labels on the image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mindices\u001b[49m\u001b[38;5;241m.\u001b[39mflatten():\n\u001b[0;32m      3\u001b[0m     x, y, w, h \u001b[38;5;241m=\u001b[39m boxes[i]\n\u001b[0;32m      4\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(class_ids[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "# Draw bounding boxes and labels on the image\n",
    "for i in indices.flatten():\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = str(class_ids[i])\n",
    "    confidence = str(round(confidences[i], 2))\n",
    "    color = (0, 255, 0)  # Green bounding box\n",
    "\n",
    "            # Draw the rectangle and put the label\n",
    "cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "cv2.putText(image, label + \" \" + confidence, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Show the image with the bounding boxes (optional)\n",
    "cv2.imshow(\"Detection\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the image with detections\n",
    "output_path = os.path.join(folder_path, \"output\", image_file)  # Make sure 'output' folder exists\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f\"Processed {image_file}\")\n",
    "    \n",
    "# Close all OpenCV windows after processing\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
